{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/iamankan/fruits-ml/blob/conference1/FruitmlTL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1a-E-BsbvUH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPa50HYhcHvc",
    "outputId": "e3b03528-cd1d-4e40-ae62-fcde0894b572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "58900480/58889256 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "w, h = (224, 224)\n",
    "base_model = keras.applications.VGG16(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(w, h, 3),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXmT2rzrcMtt"
   },
   "outputs": [],
   "source": [
    "#Freeze the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtXhn11WcPkW"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(w, h, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(inputs)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(6, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hraFj6cRnt"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zy5drwQ5cTrm"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = ImageDataGenerator()\n",
    "\n",
    "val_generator = ImageDataGenerator()\n",
    "\n",
    "test_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLmBnrTDcZGm"
   },
   "outputs": [],
   "source": [
    "train_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/train'\n",
    "test_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/test'\n",
    "val_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_fxcT66cbR_",
    "outputId": "03262fe8-8da3-4dd2-be3b-1776703f1c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11629 images belonging to 6 classes.\n",
      "Found 1289 images belonging to 6 classes.\n",
      "Found 5534 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "traingen = train_generator.flow_from_directory(train_data_dir,\n",
    "                                               target_size=(w, h),\n",
    "                                               class_mode='categorical',\n",
    "#                                                classes=class_subset,\n",
    "#                                                subset='training',\n",
    "                                               batch_size=BATCH_SIZE, \n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "validgen = val_generator.flow_from_directory(val_data_dir,\n",
    "                                               target_size=(w, h),\n",
    "                                               class_mode='categorical',\n",
    "#                                                classes=class_subset,\n",
    "#                                                subset='validation',\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               seed=42)\n",
    "\n",
    "testgen = test_generator.flow_from_directory(test_data_dir,\n",
    "                                             target_size=(w, h),\n",
    "                                             class_mode='categorical',\n",
    "#                                              classes=class_subset,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False,\n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiQ10x0gcf4_",
    "outputId": "a6b68821-ccd6-4caf-8a3d-9bc2b73c517b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "364/364 [==============================] - 169s 462ms/step - loss: 0.0866 - categorical_accuracy: 0.9987 - val_loss: 2.8151 - val_categorical_accuracy: 0.9837\n",
      "Epoch 2/20\n",
      "364/364 [==============================] - 162s 444ms/step - loss: 0.4887 - categorical_accuracy: 0.9960 - val_loss: 4.4487 - val_categorical_accuracy: 0.9783\n",
      "Epoch 3/20\n",
      "364/364 [==============================] - 161s 443ms/step - loss: 0.1369 - categorical_accuracy: 0.9982 - val_loss: 2.9418 - val_categorical_accuracy: 0.9907\n",
      "Epoch 4/20\n",
      "364/364 [==============================] - 162s 444ms/step - loss: 0.1717 - categorical_accuracy: 0.9985 - val_loss: 3.7887 - val_categorical_accuracy: 0.9845\n",
      "Epoch 5/20\n",
      "364/364 [==============================] - 162s 446ms/step - loss: 0.0643 - categorical_accuracy: 0.9995 - val_loss: 3.2562 - val_categorical_accuracy: 0.9891\n",
      "Epoch 6/20\n",
      "364/364 [==============================] - 163s 448ms/step - loss: 4.6087e-04 - categorical_accuracy: 0.9999 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 7/20\n",
      "364/364 [==============================] - 163s 447ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 8/20\n",
      "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 9/20\n",
      "364/364 [==============================] - 163s 447ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 10/20\n",
      "364/364 [==============================] - 162s 446ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 11/20\n",
      "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 12/20\n",
      "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 13/20\n",
      "364/364 [==============================] - 161s 444ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 14/20\n",
      "364/364 [==============================] - 163s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 15/20\n",
      "364/364 [==============================] - 164s 452ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 16/20\n",
      "364/364 [==============================] - 162s 444ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 17/20\n",
      "364/364 [==============================] - 164s 452ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 18/20\n",
      "364/364 [==============================] - 163s 448ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 19/20\n",
      "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
      "Epoch 20/20\n",
      "364/364 [==============================] - 165s 451ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='/content/drive/MyDrive/fruit-ml/checkpoint_file.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "history = model.fit(traingen, epochs=20, validation_data= validgen,\n",
    "              callbacks=[model_checkpoint_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8BFib-hdzKD"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM0TM4eVX6VPl7ApN/a6Akm",
   "include_colab_link": true,
   "mount_file_id": "1pRbIriyWjTTn53CvSN1n-9BFMK03YD7f",
   "name": "FruitmlTL.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
