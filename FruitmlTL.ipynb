{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FruitmlTL.ipynb",
      "provenance": [],
      "mount_file_id": "1pRbIriyWjTTn53CvSN1n-9BFMK03YD7f",
      "authorship_tag": "ABX9TyM0TM4eVX6VPl7ApN/a6Akm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamankan/fruits-ml/blob/conference1/FruitmlTL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1a-E-BsbvUH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w, h = (224, 224)\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(w, h, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPa50HYhcHvc",
        "outputId": "e3b03528-cd1d-4e40-ae62-fcde0894b572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze the base model\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "oXmT2rzrcMtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(w, h, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base_model(inputs)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(1024, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(6, activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "AtXhn11WcPkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "42hraFj6cRnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_generator = ImageDataGenerator()\n",
        "\n",
        "val_generator = ImageDataGenerator()\n",
        "\n",
        "test_generator = ImageDataGenerator()"
      ],
      "metadata": {
        "id": "Zy5drwQ5cTrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/train'\n",
        "test_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/test'\n",
        "val_data_dir = '/content/drive/MyDrive/fruit-ml/fruit_data/validation'"
      ],
      "metadata": {
        "id": "pLmBnrTDcZGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=(w, h),\n",
        "                                               class_mode='categorical',\n",
        "#                                                classes=class_subset,\n",
        "#                                                subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = val_generator.flow_from_directory(val_data_dir,\n",
        "                                               target_size=(w, h),\n",
        "                                               class_mode='categorical',\n",
        "#                                                classes=class_subset,\n",
        "#                                                subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=(w, h),\n",
        "                                             class_mode='categorical',\n",
        "#                                              classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fxcT66cbR_",
        "outputId": "03262fe8-8da3-4dd2-be3b-1776703f1c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11629 images belonging to 6 classes.\n",
            "Found 1289 images belonging to 6 classes.\n",
            "Found 5534 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/content/drive/MyDrive/fruit-ml/checkpoint_file.h5',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "history = model.fit(traingen, epochs=20, validation_data= validgen,\n",
        "              callbacks=[model_checkpoint_callback])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiQ10x0gcf4_",
        "outputId": "a6b68821-ccd6-4caf-8a3d-9bc2b73c517b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "364/364 [==============================] - 169s 462ms/step - loss: 0.0866 - categorical_accuracy: 0.9987 - val_loss: 2.8151 - val_categorical_accuracy: 0.9837\n",
            "Epoch 2/20\n",
            "364/364 [==============================] - 162s 444ms/step - loss: 0.4887 - categorical_accuracy: 0.9960 - val_loss: 4.4487 - val_categorical_accuracy: 0.9783\n",
            "Epoch 3/20\n",
            "364/364 [==============================] - 161s 443ms/step - loss: 0.1369 - categorical_accuracy: 0.9982 - val_loss: 2.9418 - val_categorical_accuracy: 0.9907\n",
            "Epoch 4/20\n",
            "364/364 [==============================] - 162s 444ms/step - loss: 0.1717 - categorical_accuracy: 0.9985 - val_loss: 3.7887 - val_categorical_accuracy: 0.9845\n",
            "Epoch 5/20\n",
            "364/364 [==============================] - 162s 446ms/step - loss: 0.0643 - categorical_accuracy: 0.9995 - val_loss: 3.2562 - val_categorical_accuracy: 0.9891\n",
            "Epoch 6/20\n",
            "364/364 [==============================] - 163s 448ms/step - loss: 4.6087e-04 - categorical_accuracy: 0.9999 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 7/20\n",
            "364/364 [==============================] - 163s 447ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 8/20\n",
            "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 9/20\n",
            "364/364 [==============================] - 163s 447ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 10/20\n",
            "364/364 [==============================] - 162s 446ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 11/20\n",
            "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 12/20\n",
            "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 13/20\n",
            "364/364 [==============================] - 161s 444ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 14/20\n",
            "364/364 [==============================] - 163s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 15/20\n",
            "364/364 [==============================] - 164s 452ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 16/20\n",
            "364/364 [==============================] - 162s 444ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 17/20\n",
            "364/364 [==============================] - 164s 452ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 18/20\n",
            "364/364 [==============================] - 163s 448ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 19/20\n",
            "364/364 [==============================] - 162s 445ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n",
            "Epoch 20/20\n",
            "364/364 [==============================] - 165s 451ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000 - val_loss: 2.5567 - val_categorical_accuracy: 0.9915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x8BFib-hdzKD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}